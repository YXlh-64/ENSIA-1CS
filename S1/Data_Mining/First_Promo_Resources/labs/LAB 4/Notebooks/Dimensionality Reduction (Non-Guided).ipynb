{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHm5TsGtzOp6"
   },
   "source": [
    "# Dimensionality Reduction: Nonlinear dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou1B_yZzzOqC"
   },
   "source": [
    "---\n",
    "# Tutorial Objectives\n",
    "\n",
    "In this notebook we'll explore how dimensionality reduction can be useful for visualizing and inferring structure in your data. To do this, we will compare PCA with t-SNE, a nonlinear dimensionality reduction method.\n",
    "\n",
    "Overview:\n",
    "- Visualize MNIST in 2D using PCA.\n",
    "- Visualize MNIST in 2D using t-SNE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJoEcyqFzOqI"
   },
   "source": [
    "---\n",
    "# Setup\n",
    "Run these cells to get the tutorial started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TqJbjYjxzOqI"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "wQCE9pPSzOqJ"
   },
   "outputs": [],
   "source": [
    "#@title Figure Settings\n",
    "import ipywidgets as widgets       # interactive display\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "m3oqJ1e7zOqK"
   },
   "outputs": [],
   "source": [
    "#@title Helper functions\n",
    "\n",
    "def visualize_components(component1, component2, labels, show=True):\n",
    "  \"\"\"\n",
    "  Plots a 2D representation of the data for visualization with categories\n",
    "  labelled as different colors.\n",
    "\n",
    "  Args:\n",
    "    component1 (numpy array of floats) : Vector of component 1 scores\n",
    "    component2 (numpy array of floats) : Vector of component 2 scores\n",
    "    labels (numpy array of floats)     : Vector corresponding to categories of\n",
    "                                         samples\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  cmap = plt.cm.get_cmap('tab10')\n",
    "  plt.scatter(x=component1, y=component2, c=labels, cmap=cmap)\n",
    "  plt.xlabel('Component 1')\n",
    "  plt.ylabel('Component 2')\n",
    "  plt.colorbar(ticks=range(10))\n",
    "  plt.clim(-0.5, 9.5)\n",
    "  if show:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkKH9PsizOqM"
   },
   "source": [
    "---\n",
    "# Section 1: Visualize MNIST in 2D using PCA\n",
    "\n",
    "In this exercise, we'll visualize the first few components of the MNIST dataset to look for evidence of structure in the data. But in this tutorial, we will also be interested in the label of each image (i.e., which numeral it is from 0 to 9). Start by running the following cell to reload the MNIST dataset (this takes a few seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qUtC5WjbzOqO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(name='mnist_784')\n",
    "X = mnist.data\n",
    "labels = [int(k) for k in mnist.target]\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXmmdha0zOqP"
   },
   "source": [
    "To perform PCA, we now will use the method implemented in sklearn. Run the following cell to set the parameters of PCA - we will only look at the top 2 components because we will be visualizing the data in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7vDoUI4AzOqP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_model = PCA(n_components=2) # Initializes PCA\n",
    "pca_model.fit(X) # Performs PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojnjtWlAzOqQ"
   },
   "source": [
    "## Exercise 1: Visualization of MNIST in 2D using PCA\n",
    "\n",
    "Fill in the code below to perform PCA and visualize the top two  components. For better visualization, take only the first 2,000 samples of the data (this will also make t-SNE much faster in the following section of the tutorial so don't skip this step!)\n",
    "\n",
    "**Suggestions:**\n",
    "- Truncate the data matrix at 2,000 samples. You will also need to truncate the array of labels.\n",
    "- Perform PCA on the truncated data.\n",
    "- Use the function `visualize_components` to plot the labelled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "U2z9lDCbzOqQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function visualize_components in module __main__:\n",
      "\n",
      "visualize_components(component1, component2, labels, show=True)\n",
      "    Plots a 2D representation of the data for visualization with categories\n",
      "    labelled as different colors.\n",
      "    \n",
      "    Args:\n",
      "      component1 (numpy array of floats) : Vector of component 1 scores\n",
      "      component2 (numpy array of floats) : Vector of component 2 scores\n",
      "      labels (numpy array of floats)     : Vector corresponding to categories of\n",
      "                                           samples\n",
      "    \n",
      "    Returns:\n",
      "      Nothing.\n",
      "\n",
      "Help on method transform in module sklearn.decomposition._base:\n",
      "\n",
      "transform(X) method of sklearn.decomposition._pca.PCA instance\n",
      "    Apply dimensionality reduction to X.\n",
      "    \n",
      "    X is projected on the first principal components previously extracted\n",
      "    from a training set.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like of shape (n_samples, n_features)\n",
      "        New data, where `n_samples` is the number of samples\n",
      "        and `n_features` is the number of features.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X_new : array-like of shape (n_samples, n_components)\n",
      "        Projection of X in the first principal components, where `n_samples`\n",
      "        is the number of samples and `n_components` is the number of the components.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(visualize_components)\n",
    "help(pca_model.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9ONRRpUgzOqR"
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "## TODO for students: take only 2,000 samples and perform PCA\n",
    "#################################################\n",
    "\n",
    "# Take only the first 2000 samples with the corresponding labels\n",
    "# X, labels = ...\n",
    "# Perform PCA\n",
    "# scores = pca_model.transform(X)\n",
    "\n",
    "# Plot the data and reconstruction\n",
    "# visualize_components(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpwoOW5YzOqR",
    "outputId": "26eb6551-87e4-463f-a503-2f8d4c3529fa"
   },
   "source": [
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=524 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/tutorials/W1D5_DimensionalityReduction/static/W1D5_Tutorial4_Solution_e53bd4fb_0.png>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3u2E2J6zOqR"
   },
   "source": [
    "## Think!\n",
    "- What do you see? Are different samples corresponding to the same numeral clustered together? Is there much overlap?\n",
    "- Do some pairs of numerals appear to be more distinguishable than others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9c4O7DhzOqS"
   },
   "source": [
    "---\n",
    "# Section 2: Visualize MNIST in 2D using t-SNE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djQHvELFzOqT"
   },
   "source": [
    "Next we will analyze the same data using t-SNE, a nonlinear dimensionality reduction method that is useful for visualizing high dimensional data in 2D or 3D. Run the cell below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "56bkKLDszOqT"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_model = TSNE(n_components=2, perplexity=30, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj1A2eBxzOqU"
   },
   "source": [
    "## Exercise 2: Apply t-SNE on MNIST\n",
    "First, we'll run t-SNE on the data to explore whether we can see more structure. The cell above defined the parameters that we will use to find our embedding (i.e, the low-dimensional representation of the data) and stored them in `model`. To run t-SNE on our data, use the function `model.fit_transform`.\n",
    "\n",
    "**Suggestions:**\n",
    "- Run t-SNE using the function `model.fit_transform`.\n",
    "- Plot the result data using `visualize_components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "X_EscuPwzOqU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit_transform in module sklearn.manifold._t_sne:\n",
      "\n",
      "fit_transform(X, y=None) method of sklearn.manifold._t_sne.TSNE instance\n",
      "    Fit X into an embedded space and return that transformed output.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : {array-like, sparse matrix} of shape (n_samples, n_features) or             (n_samples, n_samples)\n",
      "        If the metric is 'precomputed' X must be a square distance\n",
      "        matrix. Otherwise it contains a sample per row. If the method\n",
      "        is 'exact', X may be a sparse matrix of type 'csr', 'csc'\n",
      "        or 'coo'. If the method is 'barnes_hut' and the metric is\n",
      "        'precomputed', X may be a precomputed sparse graph.\n",
      "    \n",
      "    y : None\n",
      "        Ignored.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X_new : ndarray of shape (n_samples, n_components)\n",
      "        Embedding of the training data in low-dimensional space.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tsne_model.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qpxSiuElzOqV"
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "## TODO for students: perform tSNE and visualize the data\n",
    "#################################################\n",
    "\n",
    "# perform t-SNE\n",
    "embed = ...\n",
    "\n",
    "# Visualize the data\n",
    "# visualize_components(..., ..., labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enF038FszOqV",
    "outputId": "949bfb79-83f9-4809-8362-75872fce2246"
   },
   "source": [
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=522 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/tutorials/W1D5_DimensionalityReduction/static/W1D5_Tutorial4_Solution_a989b6ef_0.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5Y-0R7ozOqV"
   },
   "source": [
    "## Exercise 3: Run t-SNE with different perplexities\n",
    "\n",
    "Unlike PCA, t-SNE has a free parameter (the perplexity) that roughly determines how global vs. local information is weighted. Here we'll take a look at how the perplexity affects our interpretation of the results.\n",
    "\n",
    "**Steps:**\n",
    "- Rerun t-SNE (don't forget to re-initialize using the function `TSNE` as above) with a perplexity of 50, 5 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "B3uttM6ZzOqW"
   },
   "outputs": [],
   "source": [
    "def explore_perplexity(values):\n",
    "  \"\"\"\n",
    "  Plots a 2D representation of the data for visualization with categories\n",
    "  labelled as different colors using different perplexities.\n",
    "\n",
    "  Args:\n",
    "    values (list of floats) : list with perplexities to be visualized\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "\n",
    "  \"\"\"\n",
    "  for perp in values:\n",
    "\n",
    "    #################################################\n",
    "    ## TO DO for students: Insert your code here to redefine the t-SNE \"model\"\n",
    "    ## while setting the perplexity perform t-SNE on the data and plot the\n",
    "    ## results for perplexity = 50, 5, and 2 (set random_state to 2020\n",
    "    # Comment these lines when you complete the function\n",
    "    raise NotImplementedError(\"Student Exercise! Explore t-SNE with different perplexity\")\n",
    "    #################################################\n",
    "\n",
    "    # perform t-SNE\n",
    "    tsne_model = ...\n",
    "\n",
    "    embed = tsne_model.fit_transform(X)\n",
    "    visualize_components(embed[:, 0], embed[:, 1], labels, show=False)\n",
    "    plt.title(f\"perplexity: {perp}\")\n",
    "\n",
    "\n",
    "# Uncomment when you complete the function\n",
    "# values = [50, 5, 2]\n",
    "# explore_perplexity(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjiVpznTzOqW",
    "outputId": "bcdc9dda-f25e-4ac5-f2fc-6975a52a9756"
   },
   "source": [
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=521 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/tutorials/W1D5_DimensionalityReduction/static/W1D5_Tutorial4_Solution_e3519b37_0.png>\n",
    "\n",
    "<img alt='Solution hint' align='left' width=521 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/tutorials/W1D5_DimensionalityReduction/static/W1D5_Tutorial4_Solution_e3519b37_1.png>\n",
    "\n",
    "<img alt='Solution hint' align='left' width=522 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/tutorials/W1D5_DimensionalityReduction/static/W1D5_Tutorial4_Solution_e3519b37_2.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fe0lZBf7zOqW"
   },
   "source": [
    "## Think!\n",
    "\n",
    "- What changes compared to your previous results using perplexity equal to 50? Do you see any clusters that have a different structure than before?\n",
    "- What changes in the embedding structure for perplexity equals to 5 or 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTfs6AflzOqX"
   },
   "source": [
    "---\n",
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXxDgP-kzOqX"
   },
   "source": [
    "* We learned the difference between linear and nonlinear dimensionality reduction. While nonlinear methods can be more powerful, they can also be senseitive to noise. In contrast, linear methods are useful for their simplicity and robustness.\n",
    "* We compared PCA and t-SNE for data visualization. Using t-SNE, we could visualize clusters in the data corresponding to different digits. While PCA was able to separate some clusters (e.g., 0 vs 1), it performed poorly overall.\n",
    "* However, the results of t-SNE can change depending on the choice of perplexity. To learn more, we recommend this [Distill paper](https://distill.pub/2016/misread-tsne/).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "W1D5_Tutorial4",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
